{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([900, 100], dtype=int64))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Create an imbalanced binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=2, n_redundant=8, \n",
    "                           weights=[0.9, 0.1], flip_y=0, random_state=42)\n",
    "\n",
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 10), (1000,))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((700, 10), (700,)), ((300, 10), (300,)))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "((X_train.shape, y_train.shape), (X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       270\n",
      "           1       0.60      0.50      0.55        30\n",
      "\n",
      "    accuracy                           0.92       300\n",
      "   macro avg       0.77      0.73      0.75       300\n",
      "weighted avg       0.91      0.92      0.91       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=1, solver='liblinear')\n",
    "lr.fit(X_train, y_train)\n",
    "preds = lr.predict(X_test)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       270\n",
      "           1       0.95      0.63      0.76        30\n",
      "\n",
      "    accuracy                           0.96       300\n",
      "   macro avg       0.96      0.81      0.87       300\n",
      "weighted avg       0.96      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=45, max_depth=3)\n",
    "rf.fit(X_train, y_train)\n",
    "preds = rf.predict(X_test)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       270\n",
      "           1       0.96      0.80      0.87        30\n",
      "\n",
      "    accuracy                           0.98       300\n",
      "   macro avg       0.97      0.90      0.93       300\n",
      "weighted avg       0.98      0.98      0.98       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(eval_metric='logloss')\n",
    "xgb.fit(X_train, y_train)\n",
    "preds = xgb.predict(X_test)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-5.51207083, -5.14120195, -4.69421946, ...,  5.71550663,\n",
       "         5.79413843,  6.02415826]),\n",
       " array([1, 1, 1, ..., 1, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek(random_state=34)\n",
    "X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "np.unique(X_train_res, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       270\n",
      "           1       0.76      0.87      0.81        30\n",
      "\n",
      "    accuracy                           0.96       300\n",
      "   macro avg       0.87      0.92      0.90       300\n",
      "weighted avg       0.96      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(eval_metric='logloss')\n",
    "xgb.fit(X_train_res, y_train_res)\n",
    "preds = xgb.predict(X_test)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments tracking with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\n",
    "        'Logistic Regression',\n",
    "        LogisticRegression(C=1, solver='liblinear'),\n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ), (\n",
    "        'Random Forest',\n",
    "        RandomForestClassifier(n_estimators=45, max_depth=3),\n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ), (\n",
    "        'XGB 1',\n",
    "        XGBClassifier(eval_metric='logloss'),\n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ), (\n",
    "        'XGB 2',\n",
    "        XGBClassifier(eval_metric='logloss'),\n",
    "        (X_train_res, y_train_res),\n",
    "        (X_test, y_test)\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'0': {'precision': 0.9454545454545454,\n",
       "   'recall': 0.9629629629629629,\n",
       "   'f1-score': 0.9541284403669724,\n",
       "   'support': 270},\n",
       "  '1': {'precision': 0.6,\n",
       "   'recall': 0.5,\n",
       "   'f1-score': 0.5454545454545454,\n",
       "   'support': 30},\n",
       "  'accuracy': 0.9166666666666666,\n",
       "  'macro avg': {'precision': 0.7727272727272727,\n",
       "   'recall': 0.7314814814814814,\n",
       "   'f1-score': 0.749791492910759,\n",
       "   'support': 300},\n",
       "  'weighted avg': {'precision': 0.9109090909090909,\n",
       "   'recall': 0.9166666666666666,\n",
       "   'f1-score': 0.9132610508757297,\n",
       "   'support': 300}},\n",
       " 1: {'0': {'precision': 0.96415770609319,\n",
       "   'recall': 0.9962962962962963,\n",
       "   'f1-score': 0.9799635701275046,\n",
       "   'support': 270},\n",
       "  '1': {'precision': 0.9523809523809523,\n",
       "   'recall': 0.6666666666666666,\n",
       "   'f1-score': 0.7843137254901961,\n",
       "   'support': 30},\n",
       "  'accuracy': 0.9633333333333334,\n",
       "  'macro avg': {'precision': 0.9582693292370712,\n",
       "   'recall': 0.8314814814814815,\n",
       "   'f1-score': 0.8821386478088503,\n",
       "   'support': 300},\n",
       "  'weighted avg': {'precision': 0.9629800307219661,\n",
       "   'recall': 0.9633333333333334,\n",
       "   'f1-score': 0.9603985856637737,\n",
       "   'support': 300}},\n",
       " 2: {'0': {'precision': 0.9781818181818182,\n",
       "   'recall': 0.9962962962962963,\n",
       "   'f1-score': 0.9871559633027523,\n",
       "   'support': 270},\n",
       "  '1': {'precision': 0.96,\n",
       "   'recall': 0.8,\n",
       "   'f1-score': 0.8727272727272728,\n",
       "   'support': 30},\n",
       "  'accuracy': 0.9766666666666667,\n",
       "  'macro avg': {'precision': 0.969090909090909,\n",
       "   'recall': 0.8981481481481481,\n",
       "   'f1-score': 0.9299416180150126,\n",
       "   'support': 300},\n",
       "  'weighted avg': {'precision': 0.9763636363636364,\n",
       "   'recall': 0.9766666666666667,\n",
       "   'f1-score': 0.9757130942452044,\n",
       "   'support': 300}},\n",
       " 3: {'0': {'precision': 0.9849624060150376,\n",
       "   'recall': 0.9703703703703703,\n",
       "   'f1-score': 0.9776119402985074,\n",
       "   'support': 270},\n",
       "  '1': {'precision': 0.7647058823529411,\n",
       "   'recall': 0.8666666666666667,\n",
       "   'f1-score': 0.8125,\n",
       "   'support': 30},\n",
       "  'accuracy': 0.96,\n",
       "  'macro avg': {'precision': 0.8748341441839893,\n",
       "   'recall': 0.9185185185185185,\n",
       "   'f1-score': 0.8950559701492538,\n",
       "   'support': 300},\n",
       "  'weighted avg': {'precision': 0.962936753648828,\n",
       "   'recall': 0.96,\n",
       "   'f1-score': 0.9611007462686566,\n",
       "   'support': 300}}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = {}\n",
    "\n",
    "for i, mod in enumerate(models):\n",
    "    model_name = mod[0]\n",
    "    model = mod[1]\n",
    "    model.fit(mod[2][0], mod[2][1])\n",
    "    preds = model.predict(mod[3][0])\n",
    "    report = classification_report(mod[3][1], preds, output_dict=True)\n",
    "    metrics[i] = report\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/18 07:29:41 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/08/18 07:29:41 INFO mlflow.tracking._tracking_service.client: 🏃 View run Logistic Regression at: http://127.0.0.1:5000//#/experiments/338671186205244746/runs/8c8035d4b4e74bf7988d9219fb762acb.\n",
      "2024/08/18 07:29:41 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000//#/experiments/338671186205244746.\n",
      "2024/08/18 07:29:44 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/08/18 07:29:44 INFO mlflow.tracking._tracking_service.client: 🏃 View run Random Forest at: http://127.0.0.1:5000//#/experiments/338671186205244746/runs/b06ee82cc38b4d8490024bc4752f24bb.\n",
      "2024/08/18 07:29:44 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000//#/experiments/338671186205244746.\n",
      "2024/08/18 07:29:46 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/08/18 07:29:46 INFO mlflow.tracking._tracking_service.client: 🏃 View run XGB 1 at: http://127.0.0.1:5000//#/experiments/338671186205244746/runs/9a0138b1d68447cb9fa8ae5175c612a7.\n",
      "2024/08/18 07:29:46 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000//#/experiments/338671186205244746.\n",
      "2024/08/18 07:29:48 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/08/18 07:29:48 INFO mlflow.tracking._tracking_service.client: 🏃 View run XGB 2 at: http://127.0.0.1:5000//#/experiments/338671186205244746/runs/b6c9b44985b94d9fbe9c07b1b0b113aa.\n",
      "2024/08/18 07:29:48 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000//#/experiments/338671186205244746.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_experiment(\"multiple_models\")\n",
    "mlflow.set_registry_uri(uri=\"http://127.0.0.1:5000/\")\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    model_name = model[0]\n",
    "    model = model[1]\n",
    "    report = metrics[i]\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        mlflow.log_param('model', model_name)\n",
    "        mlflow.log_metric('accuracy', report['accuracy'])\n",
    "        mlflow.log_metric('recall_0', report['0']['recall'])\n",
    "        mlflow.log_metric('recall_1', report['1']['recall'])\n",
    "        mlflow.log_metric('f1-score', report['macro avg']['f1-score'])\n",
    "        if 'xgb' in model_name:\n",
    "            mlflow.xgboost.log_model(model, 'model')\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

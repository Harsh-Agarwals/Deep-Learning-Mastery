{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch\n",
    "\n",
    "- open-source (by Facebook - Saumith Chintala)\n",
    "- for building and training NN\n",
    "- flexible\n",
    "- efficient\n",
    "- GPU support\n",
    "- fast\n",
    "- support for other libraries(huggingFace, langchain, etc)\n",
    "- Wide uses\n",
    "\n",
    "### Key Features\n",
    "**Dynamic Computational Graphs**: Data flow through the graph is flexible and depends on the input structure. Different graphs for different batches (exp NLP where we need padding, now with DCGs, we can do padding at the batch levels rather than the global level.)\n",
    "**Graphs is built on the fly as the operations are executed** i.e. structure of the graphs are determined during runtime based on the data flowing through it.\n",
    "\n",
    "**GPU Acceleration**: built in CUDA features\n",
    "\n",
    "**Autograd functionality**: enables automatic computations of gradients, simplifying implementation of backpropagation\n",
    "\n",
    "## PyTorch API\n",
    "\n",
    "- Working with data\n",
    "- Creating Models\n",
    "- Optimizing the Model Parameters\n",
    "- Saving Models\n",
    "- Loading Models\n",
    "\n",
    "#### Working with data\n",
    "\n",
    "- _**torch.utils.data.DataLoader**_: wraps an iterable around the Dataset\n",
    "- _**torch.utils.data.Dataset**_: stores samples and their corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:22<00:00, 1151834.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 360389.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:01<00:00, 2461669.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train X: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64])\n",
      "Shape of test X: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=training_data,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "for X, y in train_dataloader:\n",
    "    print(f\"Shape of train X: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape}\")\n",
    "    break\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of test X: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Means each data point (image) is 28x28 with 64 images in each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset FashionMNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: ToTensor(),\n",
       " Dataset FashionMNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: ToTensor())"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total 60000 images in Train and 10000 in test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Models\n",
    "\n",
    "- _**nn.Module**_: Creating a class that inherits from nn.Module\n",
    "- _**__init__**_: define layers of the network in the __init__ function\n",
    "- _**forward**_: define how data will pass through the network in forward function\n",
    "- _**GPU instance**_: to accelerate operations in NN, we move class instance to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device=device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the Model Parameters\n",
    "\n",
    "We need a loss function and an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<generator object Module.parameters at 0x00000223D940F220>,\n",
       " CrossEntropyLoss(),\n",
       " SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     differentiable: False\n",
       "     foreach: None\n",
       "     lr: 0.001\n",
       "     maximize: False\n",
       "     momentum: 0\n",
       "     nesterov: False\n",
       "     weight_decay: 0\n",
       " ))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=1e-3)\n",
    "\n",
    "model.parameters(), loss_function, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In single loop, model makes predictions on training set (few to it in batches), and backpropagates the error to adjust the model's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_function, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute predictions\n",
    "        pred = model(X)\n",
    "        loss = loss_function(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch%100==0:\n",
    "            loss, current = loss.item(), (batch+1)*len(X)\n",
    "            print(f\"Loss: {loss}, current: [{current}/{size}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**loss.backward()**: calculated the gradients of the loss w.r.t each parameter\n",
    "\n",
    "**optimizer.step()**: once we have our gradients, optimizer.step() adjusts the parameters by the gradients collected in loss.backward()\n",
    "\n",
    "**optimizer.zero_grad()**: reset the gradients of model parameters. Gradients by defaults add up, to prevent double counting, we set them to zeros at each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_function):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_function(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test error: \\n Accuracy: {correct*100}, Avg. Loss: {test_loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model.train()**: tells model that you are training the model. This helps inform layers like Dropout and BatchNorm, which are designed to behave differently during training and evaluation. \n",
    "\n",
    "**model.eval()**: tells the model that you are evaluating.\n",
    "\n",
    "**torch.no_grad()**: ensures no grads are calculated during testing, prevents unnecessary calculations, saves memory and time\n",
    "\n",
    "Training over several epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Loss: 2.1852340698242188, current: [64/60000]\n",
      "Loss: 2.1673810482025146, current: [6464/60000]\n",
      "Loss: 2.1269333362579346, current: [12864/60000]\n",
      "Loss: 2.14335560798645, current: [19264/60000]\n",
      "Loss: 2.091064214706421, current: [25664/60000]\n",
      "Loss: 2.0306830406188965, current: [32064/60000]\n",
      "Loss: 2.0656158924102783, current: [38464/60000]\n",
      "Loss: 1.9896384477615356, current: [44864/60000]\n",
      "Loss: 2.0044243335723877, current: [51264/60000]\n",
      "Loss: 1.9353084564208984, current: [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 53.290000000000006, Avg. Loss: 1.9290706891163139\n",
      "Epoch: 2\n",
      "Loss: 1.9601246118545532, current: [64/60000]\n",
      "Loss: 1.9209266901016235, current: [6464/60000]\n",
      "Loss: 1.8250185251235962, current: [12864/60000]\n",
      "Loss: 1.869011402130127, current: [19264/60000]\n",
      "Loss: 1.7492424249649048, current: [25664/60000]\n",
      "Loss: 1.7017980813980103, current: [32064/60000]\n",
      "Loss: 1.7345941066741943, current: [38464/60000]\n",
      "Loss: 1.6324387788772583, current: [44864/60000]\n",
      "Loss: 1.6658046245574951, current: [51264/60000]\n",
      "Loss: 1.566882848739624, current: [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 59.06, Avg. Loss: 1.5737294042186372\n",
      "Epoch: 3\n",
      "Loss: 1.6379221677780151, current: [64/60000]\n",
      "Loss: 1.589483618736267, current: [6464/60000]\n",
      "Loss: 1.4600651264190674, current: [12864/60000]\n",
      "Loss: 1.5292679071426392, current: [19264/60000]\n",
      "Loss: 1.4016708135604858, current: [25664/60000]\n",
      "Loss: 1.4015650749206543, current: [32064/60000]\n",
      "Loss: 1.4169577360153198, current: [38464/60000]\n",
      "Loss: 1.337321400642395, current: [44864/60000]\n",
      "Loss: 1.3758926391601562, current: [51264/60000]\n",
      "Loss: 1.2820359468460083, current: [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 62.56, Avg. Loss: 1.2988062671795013\n",
      "Epoch: 4\n",
      "Loss: 1.3769917488098145, current: [64/60000]\n",
      "Loss: 1.3427176475524902, current: [6464/60000]\n",
      "Loss: 1.1967551708221436, current: [12864/60000]\n",
      "Loss: 1.2949985265731812, current: [19264/60000]\n",
      "Loss: 1.1663414239883423, current: [25664/60000]\n",
      "Loss: 1.196128487586975, current: [32064/60000]\n",
      "Loss: 1.213757872581482, current: [38464/60000]\n",
      "Loss: 1.146367073059082, current: [44864/60000]\n",
      "Loss: 1.1895561218261719, current: [51264/60000]\n",
      "Loss: 1.1085823774337769, current: [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 64.27000000000001, Avg. Loss: 1.1232665500063805\n",
      "Epoch: 5\n",
      "Loss: 1.197993516921997, current: [64/60000]\n",
      "Loss: 1.1809146404266357, current: [6464/60000]\n",
      "Loss: 1.0198724269866943, current: [12864/60000]\n",
      "Loss: 1.14751398563385, current: [19264/60000]\n",
      "Loss: 1.0153980255126953, current: [25664/60000]\n",
      "Loss: 1.055855631828308, current: [32064/60000]\n",
      "Loss: 1.0851458311080933, current: [38464/60000]\n",
      "Loss: 1.023077130317688, current: [44864/60000]\n",
      "Loss: 1.067312240600586, current: [51264/60000]\n",
      "Loss: 0.9967489838600159, current: [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 65.7, Avg. Loss: 1.0078350214441871\n",
      "Done\n",
      "CPU times: total: 6.81 s\n",
      "Wall time: 38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 5\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(f\"Epoch: {i+1}\")\n",
    "    train(train_dataloader, model, loss_function, optimizer)\n",
    "    test(test_dataloader, model, loss_function)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 7, 3, 4, 1, 2, 4, 8, 0, 2, 5, 7, 9,\n",
      "        1, 4, 6, 0, 9, 3, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 6, 1, 3, 7, 6, 7, 2, 1,\n",
      "        2, 2, 4, 4, 5, 8, 2, 2, 8, 4, 8, 0, 7, 7, 8, 5])\n",
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-3.0277, -3.3167, -0.8365, -2.5314, -0.8681,  3.1824, -1.0871,  3.2341,\n",
       "           2.2635,  3.8444]], grad_fn=<AddmmBackward0>),\n",
       " tensor([9]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for X, y in test_dataloader:\n",
    "    print(X, y)\n",
    "    print(X.shape, y.shape)\n",
    "    break\n",
    "pred = model(X[0])\n",
    "pred, pred.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(64, torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for X, y in test_dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        print(X, y.shape)\n",
    "        break\n",
    "\n",
    "len(X), X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.0277, -3.3167, -0.8365, -2.5314, -0.8681,  3.1824, -1.0871,  3.2341,\n",
       "          2.2635,  3.8444]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(X[0])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.argmax(pred).item() == y[0]).type(torch.float).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([True]), True, tensor([1.]), tensor(1.), tensor([True]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.argmax(1) == y[0], (pred.argmax(1) == y[0]).item(), (pred.argmax(1) == y[0]).type(torch.float), (pred.argmax(1) == y[0]).type(torch.float).sum(), torch.argmax(pred, 1) == y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.0277, -3.3167, -0.8365, -2.5314, -0.8681,  3.1824, -1.0871,  3.2341,\n",
       "          2.2635,  3.8444],\n",
       "        [ 1.2637, -3.4860,  4.3094, -1.0402,  3.7479, -2.1592,  3.2621, -3.9865,\n",
       "          2.0015, -2.5964],\n",
       "        [ 1.8172,  5.7545, -0.1377,  4.0086,  0.9133, -3.1278,  0.7877, -3.9263,\n",
       "         -2.1961, -4.0858],\n",
       "        [ 1.1486,  4.4776, -0.2569,  3.1102,  0.4883, -2.2147,  0.4146, -2.8601,\n",
       "         -1.8106, -2.8417],\n",
       "        [ 1.1762, -1.6343,  1.8896, -0.1472,  1.8013, -1.2123,  1.8479, -2.3607,\n",
       "          1.0001, -1.5686]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(X[0:5])\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([9, 2, 1, 1, 2]), tensor([9, 2, 1, 1, 6]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(preds, 1), y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.argmax(preds, 1) == y[:5]).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Models\n",
    "\n",
    "Common way to save a model is to serialize the internal state dictionary, containing the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Models\n",
    "\n",
    "Recreating the model structure and loading the state dictionary into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device=device)\n",
    "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

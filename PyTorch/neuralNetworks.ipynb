{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device=device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image = torch.rand(3, 28, 28)\n",
    "input_image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flatten(\n",
       "  start_dim=tensor([[[0.2700, 0.7621, 0.3250,  ..., 0.6522, 0.1220, 0.6495],\n",
       "           [0.7116, 0.9336, 0.4894,  ..., 0.4058, 0.7238, 0.7750],\n",
       "           [0.1239, 0.2541, 0.1276,  ..., 0.8847, 0.2155, 0.4042],\n",
       "           ...,\n",
       "           [0.0144, 0.6862, 0.9755,  ..., 0.8096, 0.4337, 0.3354],\n",
       "           [0.3220, 0.7303, 0.9609,  ..., 0.6713, 0.9697, 0.5882],\n",
       "           [0.9907, 0.8336, 0.4483,  ..., 0.5658, 0.8442, 0.8156]],\n",
       "  \n",
       "          [[0.7987, 0.6640, 0.6771,  ..., 0.3630, 0.7756, 0.5806],\n",
       "           [0.9725, 0.7236, 0.9784,  ..., 0.8632, 0.2418, 0.0656],\n",
       "           [0.8514, 0.4610, 0.0559,  ..., 0.3047, 0.8123, 0.1079],\n",
       "           ...,\n",
       "           [0.5064, 0.0640, 0.3589,  ..., 0.8371, 0.7285, 0.7498],\n",
       "           [0.5187, 0.3138, 0.1296,  ..., 0.7874, 0.5351, 0.5901],\n",
       "           [0.4970, 0.4476, 0.1411,  ..., 0.1336, 0.4723, 0.1587]],\n",
       "  \n",
       "          [[0.5598, 0.8237, 0.4349,  ..., 0.4438, 0.9460, 0.0798],\n",
       "           [0.4443, 0.4712, 0.7205,  ..., 0.8804, 0.4320, 0.2721],\n",
       "           [0.7941, 0.9509, 0.0977,  ..., 0.5088, 0.9124, 0.9268],\n",
       "           ...,\n",
       "           [0.5897, 0.5284, 0.6941,  ..., 0.9522, 0.5660, 0.8179],\n",
       "           [0.2476, 0.3911, 0.7877,  ..., 0.9211, 0.4889, 0.8448],\n",
       "           [0.5190, 0.3802, 0.1152,  ..., 0.7404, 0.5385, 0.6785]]]), end_dim=-1\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Flatten(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 784])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_img = flatten(input_image)\n",
    "flat_img.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1 = nn.Linear(28*28, 512)\n",
    "hidden1 = layer1(flat_img)\n",
    "hidden1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu = nn.ReLU()\n",
    "relu1 = relu(hidden1)\n",
    "relu1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_module = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    relu,\n",
    "    nn.Linear(512, 10)\n",
    ")\n",
    "\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "logits = seq_module(input_image)\n",
    "logits.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1675,  0.0924, -0.1812,  0.1361,  0.1471, -0.1205, -0.0392, -0.0821,\n",
       "         -0.0189,  0.0440],\n",
       "        [-0.1663,  0.0568, -0.2115,  0.0594,  0.1783, -0.1707, -0.0714, -0.0479,\n",
       "         -0.0140,  0.0200],\n",
       "        [-0.1194, -0.0048, -0.1295, -0.0157, -0.0554, -0.1065, -0.2241,  0.0430,\n",
       "         -0.0420, -0.0179]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MercadosEMI\\anaconda3\\envs\\genai\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0856, 0.1111, 0.0845, 0.1160, 0.1173, 0.0898, 0.0974, 0.0933, 0.0994,\n",
       "         0.1058],\n",
       "        [0.0873, 0.1091, 0.0834, 0.1094, 0.1232, 0.0869, 0.0959, 0.0982, 0.1016,\n",
       "         0.1051],\n",
       "        [0.0947, 0.1062, 0.0937, 0.1050, 0.1009, 0.0959, 0.0852, 0.1114, 0.1023,\n",
       "         0.1048]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x000002343AED7D80>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.named_parameters at 0x000002343C543D40>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

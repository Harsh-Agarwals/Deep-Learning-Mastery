{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3de17c0-8772-407c-9e30-d218187f6251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "from IPython.display import display, Math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841c6ae0-6f4c-495b-b140-672cbda5259e",
   "metadata": {},
   "source": [
    "## Using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "152110ce-50c6-406a-98ab-20f57e05921a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([2.0], requires_grad=True)\n",
    "b = torch.tensor([3.0], requires_grad=True)\n",
    "c = torch.tensor([5.0], requires_grad=True)\n",
    "d = torch.tensor([10.0], requires_grad=True)\n",
    "\n",
    "t = torch.log(d)\n",
    "\n",
    "u = a*b\n",
    "v = t*c\n",
    "\n",
    "# retain_grad() allows us to calculate grad of a varible despite it not being a leaf node\n",
    "t.retain_grad()\n",
    "u.retain_grad()\n",
    "e = u+v\n",
    "\n",
    "a.requires_grad, t.requires_grad, u.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59f11f39-061d-46ac-9e8d-0a499dee030a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6.], grad_fn=<MulBackward0>),\n",
       " tensor([11.5129], grad_fn=<MulBackward0>),\n",
       " tensor([17.5129], grad_fn=<AddBackward0>),\n",
       " tensor([2.3026], grad_fn=<LogBackward0>))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u, v, e, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "133c4ed3-7bde-4c1f-a2d4-4b5a7b3f7b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is leaf: True\n",
      "a.grad_fn: None\n",
      "a.grad: None\n",
      "\n",
      "b is leaf: True\n",
      "b.grad_fn: None\n",
      "b.grad: None\n",
      "\n",
      "c is leaf: True\n",
      "c.grad_fn: None\n",
      "c.grad: None\n",
      "\n",
      "d is leaf: True\n",
      "d.grad_fn: None\n",
      "d.grad: None\n",
      "\n",
      "t is leaf: False\n",
      "t.grad_fn: <LogBackward0 object at 0x0000023BBFB9F970>\n",
      "t.grad: None\n",
      "\n",
      "e is leaf: False\n",
      "e.grad_fn: <AddBackward0 object at 0x0000023BBFB9F970>\n",
      "e.grad: None\n",
      "\n",
      "u is leaf: False\n",
      "u.grad_fn: <MulBackward0 object at 0x0000023BBFB9F970>\n",
      "u.grad: None\n",
      "\n",
      "v is leaf: False\n",
      "v.grad_fn: <MulBackward0 object at 0x0000023BBFB9F970>\n",
      "v.grad: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'a is leaf: {a.is_leaf}') # variables which are directly created by the user are leaf node\n",
    "print(f'a.grad_fn: {a.grad_fn}')\n",
    "print(f'a.grad: {a.grad}\\n')\n",
    "\n",
    "print(f'b is leaf: {b.is_leaf}')\n",
    "print(f'b.grad_fn: {b.grad_fn}')\n",
    "print(f'b.grad: {b.grad}\\n')\n",
    "\n",
    "print(f'c is leaf: {c.is_leaf}')\n",
    "print(f'c.grad_fn: {c.grad_fn}')\n",
    "print(f'c.grad: {c.grad}\\n')\n",
    "\n",
    "print(f'd is leaf: {d.is_leaf}')\n",
    "print(f'd.grad_fn: {d.grad_fn}')\n",
    "print(f'd.grad: {d.grad}\\n')\n",
    "\n",
    "print(f't is leaf: {t.is_leaf}') # varaibles not created by the user and which depends on other varibles are not leaf node\n",
    "print(f't.grad_fn: {t.grad_fn}')\n",
    "print(f't.grad: {t.grad}\\n')\n",
    "\n",
    "print(f'e is leaf: {e.is_leaf}')\n",
    "print(f'e.grad_fn: {e.grad_fn}')\n",
    "print(f'e.grad: {e.grad}\\n')\n",
    "\n",
    "print(f'u is leaf: {u.is_leaf}')\n",
    "print(f'u.grad_fn: {u.grad_fn}')\n",
    "print(f'u.grad: {u.grad}\\n')\n",
    "\n",
    "print(f'v is leaf: {v.is_leaf}')\n",
    "print(f'v.grad_fn: {v.grad_fn}')\n",
    "print(f'v.grad: {v.grad}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98334671-e662-4460-8d48-822e969ca9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8adadd1a-4574-4b5e-bc6f-6cbb4d31566b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5.]), tensor([1.]), None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.grad, u.grad, v.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6a1ca10-923a-4a20-8a3e-befe19531a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.]), tensor([2.]), tensor([2.3026]), tensor([0.5000]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad, b.grad, c.grad, d.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46cd08c8-35de-46b4-9260-4646a61b2618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is leaf: True\n",
      "a.grad_fn: None\n",
      "a.grad: tensor([3.])\n",
      "\n",
      "b is leaf: True\n",
      "b.grad_fn: None\n",
      "b.grad: tensor([2.])\n",
      "\n",
      "c is leaf: True\n",
      "c.grad_fn: None\n",
      "c.grad: tensor([2.3026])\n",
      "\n",
      "d is leaf: True\n",
      "d.grad_fn: None\n",
      "d.grad: tensor([0.5000])\n",
      "\n",
      "t is leaf: False\n",
      "t.grad_fn: <LogBackward0 object at 0x0000023BBFB9F970>\n",
      "t.grad: tensor([5.])\n",
      "\n",
      "e is leaf: False\n",
      "e.grad_fn: <AddBackward0 object at 0x0000023BBFB9F970>\n",
      "e.grad: None\n",
      "\n",
      "u is leaf: False\n",
      "u.grad_fn: <MulBackward0 object at 0x0000023BBFB9F970>\n",
      "u.grad: tensor([1.])\n",
      "\n",
      "v is leaf: False\n",
      "v.grad_fn: <MulBackward0 object at 0x0000023BBFB9F970>\n",
      "v.grad: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'a is leaf: {a.is_leaf}')\n",
    "print(f'a.grad_fn: {a.grad_fn}')\n",
    "print(f'a.grad: {a.grad}\\n')\n",
    "\n",
    "print(f'b is leaf: {b.is_leaf}')\n",
    "print(f'b.grad_fn: {b.grad_fn}')\n",
    "print(f'b.grad: {b.grad}\\n')\n",
    "\n",
    "print(f'c is leaf: {c.is_leaf}')\n",
    "print(f'c.grad_fn: {c.grad_fn}')\n",
    "print(f'c.grad: {c.grad}\\n')\n",
    "\n",
    "print(f'd is leaf: {d.is_leaf}')\n",
    "print(f'd.grad_fn: {d.grad_fn}')\n",
    "print(f'd.grad: {d.grad}\\n')\n",
    "\n",
    "print(f't is leaf: {t.is_leaf}')\n",
    "print(f't.grad_fn: {t.grad_fn}')\n",
    "print(f't.grad: {t.grad}\\n')\n",
    "\n",
    "print(f'e is leaf: {e.is_leaf}')\n",
    "print(f'e.grad_fn: {e.grad_fn}')\n",
    "print(f'e.grad: {e.grad}\\n')\n",
    "\n",
    "print(f'u is leaf: {u.is_leaf}')\n",
    "print(f'u.grad_fn: {u.grad_fn}')\n",
    "print(f'u.grad: {u.grad}\\n')\n",
    "\n",
    "print(f'v is leaf: {v.is_leaf}')\n",
    "print(f'v.grad_fn: {v.grad_fn}')\n",
    "print(f'v.grad: {v.grad}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bf0034c-0547-4e66-a1b9-710c498ce8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.backward() => This won't run as its value is deleted by the system to save memory. If we want to run it, use retain_graph=True in previous e.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5da72ed4-9509-49aa-b8a8-5251bc9053f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.backward() # this ran as retain_graph was set True this time. (Though it will run only once unless retain_graph is set here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7a6ef8-26e5-478b-ac7c-91cae30fa868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cdffe63-9c5f-42b5-8a95-d037711d1012",
   "metadata": {},
   "source": [
    "## Using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1aa71648-1d6c-4c0f-83cb-5a2b3abde47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tf.float32,\n",
       " TensorShape([]),\n",
       " 0,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=1>,\n",
       " <tf.Tensor: shape=(0,), dtype=int32, numpy=array([], dtype=int32)>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant(2.0)\n",
    "a.dtype, a.shape, a.ndim, tf.size(a), tf.shape(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8e8c61c-af68-4cf5-876c-4ed8d143bacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=2.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=17.512926>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=11.512926>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.3025851>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant(2.0)\n",
    "b = tf.constant(3.0)\n",
    "c = tf.constant(5.0)\n",
    "d = tf.constant(10.0)\n",
    "\n",
    "t = tf.math.log(d)\n",
    "\n",
    "u = tf.multiply(a, b)\n",
    "v = tf.multiply(t, c)\n",
    "\n",
    "e = tf.add(u, v)\n",
    "\n",
    "a, e, u, v, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0c88fd4-cc10-47b4-a5f5-320a6ee1cb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch([a, b, c, d])\n",
    "    t = tf.math.log(d)\n",
    "    u = tf.multiply(a, b)\n",
    "    v = tf.multiply(t, c)\n",
    "    e = tf.add(u, v)\n",
    "    \n",
    "gradients = tape.gradient(e, [a, b, c, d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5a9b182-55a0-4c58-9f39-6cb9ace5f3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=3.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.3025851>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.5>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b20fc326-6f3a-4679-9827-45b97bc26000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients= a:3.0, b: 2.0, c: 2.30, d: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Gradients= a:{gradients[0]}, b: {gradients[1]}, c: {gradients[2]:.2f}, d: {gradients[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd9015f-b169-4d73-8894-23caef2af9d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

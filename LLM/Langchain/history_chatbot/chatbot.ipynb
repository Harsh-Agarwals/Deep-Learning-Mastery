{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq.chat_models import ChatGroq\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000282A9CF6750>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000282A9CF7290>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********')),\n",
       " StrOutputParser())"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ChatGroq(\n",
    "    model=\"gemma2-9b-it\",\n",
    "    api_key=GROQ_API_KEY,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "model, parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"That's fantastic, Harsh! Starting your own startup is an exciting and challenging journey. \\n\\nI can help you brainstorm ideas, research markets, or even just bounce ideas off of. \\n\\nTell me, what kind of startup are you interested in? What are your passions and skills? \\n\\nThe more information you give me, the better I can assist you in your entrepreneurial endeavors.  üöÄ\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 24, 'total_tokens': 108, 'completion_time': 0.152727273, 'prompt_time': 0.000150489, 'queue_time': 0.01464128, 'total_time': 0.152877762}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-8ec17373-c7d3-4995-a57f-45a182a3a24a-0', usage_metadata={'input_tokens': 24, 'output_tokens': 84, 'total_tokens': 108})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"Hello, my name is Harsh and I aspire to start my own startup.\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are Harsh, a data scientist with a passion for deep tech!  You excel at machine learning, are expanding your knowledge into NLP and generative AI, and even have skills in web development and DevOps. You're looking to leverage these skills to launch your own deep tech startup. \\n\\nIs there anything specific you'd like to brainstorm or explore about your potential startup? For example:\\n\\n* **What problems are you passionate about solving?**\\n* **What industries excite you?**\\n* **Are there any particular deep tech applications you find intriguing?**\\n\\n\\nLet's work together to shape your vision! \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 131, 'prompt_tokens': 94, 'total_tokens': 225, 'completion_time': 0.238181818, 'prompt_time': 0.003443027, 'queue_time': 0.03453634, 'total_time': 0.241624845}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-05c4a549-d69e-4a74-932c-783cc35f6cd8-0', usage_metadata={'input_tokens': 94, 'output_tokens': 131, 'total_tokens': 225})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([\n",
    "    HumanMessage(content=\"Hello, my name is Harsh and I aspire to start my own deep tech startup. I work as a data scientist, is good with Machine Learning and stuffs, currently learning NLP and generative AI. I also can build websites and do DevOps.\"),\n",
    "    AIMessage(content=\"That's great, tell me what type of startup you aspire to build.\"),\n",
    "    HumanMessage(content=\"Hey, who and I and what do I do?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in sessions:\n",
    "        sessions[session_id] = ChatMessageHistory()\n",
    "    return sessions[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat1\"}}\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"That's fantastic, Harsh!  It sounds like you've got a great foundation for a deep tech startup.  Combining your expertise in data science, machine learning, NLP, generative AI, web development, and DevOps gives you a powerful edge.  \\n\\nTo help you brainstorm, let's explore some potential deep tech startup ideas:\\n\\n**Leveraging Your Skills:**\\n\\n* **AI-Powered Content Creation:** Build tools that use generative AI to help businesses create high-quality content (articles, marketing copy, social media posts, etc.) at scale.\\n* **Personalized Learning Platform:** Develop an AI-driven platform that adapts to each student's learning style and pace, providing personalized educational content and support.\\n* **Predictive Maintenance for Industries:** Apply machine learning to analyze sensor data and predict equipment failures in manufacturing, transportation, or other sectors, reducing downtime and costs.\\n* **Conversational AI for Customer Service:** Create chatbots or virtual assistants that use NLP to provide efficient and personalized customer support, answering FAQs and resolving issues.\\n* **AI-Driven Healthcare Diagnosis:** Develop algorithms that analyze medical images or patient data to assist doctors in making faster and more accurate diagnoses.\\n\\n**Considering Market Needs:**\\n\\n* **Identify a specific industry or problem:**  What challenges are businesses or individuals facing that AI could potentially solve?\\n* **Research existing solutions:**  Are there any existing solutions, and how can your approach be more innovative or effective?\\n* **Validate your idea:** Talk to potential customers and get their feedback on the problem and your proposed solution.\\n\\n**Important Considerations:**\\n\\n* **Data Access:**  Deep learning models require large datasets for training.  Ensure you have access to the necessary data or can acquire it ethically and legally.\\n* **Technical Expertise:**  Building a deep tech startup requires a strong technical team.  Consider your own skills and whether you need to bring in additional expertise.\\n* **Funding:** Deep tech startups often require significant funding for research and development. Explore various funding options, such as grants, venture capital, or angel investors.\\n* **Ethical Implications:** Be mindful of the ethical implications of your AI technology.  Consider issues such as bias, fairness, transparency, and accountability.\\n\\n\\n\\nRemember, starting a successful deep tech startup is a journey that requires dedication, perseverance, and a willingness to learn and adapt. Best of luck, Harsh! I'm excited to see what you create.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 500, 'prompt_tokens': 57, 'total_tokens': 557, 'completion_time': 0.909090909, 'prompt_time': 0.002050518, 'queue_time': 0.011765861, 'total_time': 0.911141427}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-bdc2074a-119c-44ab-95b7-5084ff9ad942-0', usage_metadata={'input_tokens': 57, 'output_tokens': 500, 'total_tokens': 557})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hello, my name is Harsh and I aspire to start my own deep tech startup. I work as a data scientist, is good with Machine Learning and stuffs, currently learning NLP and generative AI. I also can build websites and do DevOps.\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're on fire, Harsh!  Let's  keep the creative juices flowing. How about this:\n",
      "\n",
      "**Idea: AI-Powered Music Collaboration Platform**\n",
      "\n",
      "**Problem:**\n",
      "\n",
      "* Musicians often struggle to find collaborators with complementary skills and styles.\n",
      "*  Traditional music production can be time-consuming and geographically limited.\n",
      "\n",
      "**Solution:**\n",
      "\n",
      "* **Platform:** A web-based platform that connects musicians from diverse backgrounds and genres.\n",
      "* **AI-Driven Matching:**  Use NLP and machine learning to analyze musicians' musical styles, preferences, and collaboration history to suggest compatible partners.\n",
      "* **Collaborative Workspace:**  Provide a virtual studio environment where musicians can share ideas, experiment with sounds, and co-create music in real-time, regardless of location.\n",
      "* **AI-Assisted Composition:**  Integrate generative AI tools that can help musicians overcome creative blocks, explore new musical ideas, and generate melodies, harmonies, or even entire song structures.\n",
      "* **Performance & Distribution:**  Offer tools for musicians to showcase their collaborative work, connect with potential fans, and distribute their music online.\n",
      "\n",
      "**Your Strengths:**\n",
      "\n",
      "* **Data Science & Machine Learning:**  Build the AI algorithms for matching musicians, analyzing musical styles, and powering the composition assistance features.\n",
      "* **NLP:**  Analyze lyrics, song structures, and musical themes to enhance the matching process and understand musicians' creative intentions.\n",
      "* **Generative AI:**  Develop AI models that can generate musical elements and assist in the composition process.\n",
      "* **Web Development & DevOps:**  Create a user-friendly and scalable platform for musicians to collaborate and share their work.\n",
      "\n",
      "**Market Potential:**\n",
      "\n",
      "*  A massive global community of musicians looking for new ways to connect, collaborate, and create.\n",
      "\n",
      "**Next Steps:**\n",
      "\n",
      "* **Music Genre Research:**  Identify specific music genres where AI-assisted collaboration could be particularly valuable.\n",
      "* **User Interface Design:**  Create a visually appealing and intuitive platform that caters to the needs of musicians.\n",
      "* **Beta Testing:**  Gather feedback from musicians on the platform's features and functionality to refine and improve the product.\n",
      "\n",
      "\n",
      "\n",
      "Remember, Harsh, the key is to focus on solving a real problem for a specific target audience.  This idea combines your passions for AI and music, giving you the potential to make a significant impact on the creative industry.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config2 = {\"configurable\": {\"session_id\": \"chat1\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Can you suggest me something?\")],\n",
    "    config=config2\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide me with some context! I need to know what kind of ideas you're looking for. \n",
      "\n",
      "For example, tell me:\n",
      "\n",
      "* **What is the topic?** (e.g., writing a story, planning a party, solving a problem)\n",
      "* **What have you already considered?** \n",
      "* **What are your goals?** (e.g., be creative, be practical, be funny)\n",
      "* **What is your target audience?** (e.g., children, adults, experts)\n",
      "\n",
      "\n",
      "The more information you give me, the better I can help! üòä \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config3 = {\"configurable\": {\"session_id\": \"chat2\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Give me some more ideas.\")],\n",
    "    config=config3\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're on a roll, Harsh! Let's keep the brainstorming going. Here are a few more deep tech startup ideas tailored to your skillset:\n",
      "\n",
      "**1. AI-Powered Legal Document Analysis & Summarization:**\n",
      "\n",
      "* **Problem:**  Legal documents are often complex, lengthy, and time-consuming to review.\n",
      "* **Solution:** Develop an AI-powered platform that uses NLP to analyze legal documents (contracts, patents, case law) and automatically generate concise summaries, highlight key clauses, and identify potential risks or opportunities.\n",
      "* **Your Strengths:**  NLP, ML, web development.\n",
      "\n",
      "**2. AI-Driven Personalized Mental Wellness Coach:**\n",
      "\n",
      "* **Problem:**  Access to mental health care is often limited and expensive.\n",
      "* **Solution:** Create an AI-powered app that provides personalized cognitive behavioral therapy (CBT) techniques, mindfulness exercises, and mood tracking based on user input and data analysis. \n",
      "* **Your Strengths:** ML, NLP, potentially integrate with wearables for biofeedback.\n",
      "\n",
      "**3. AI-Enhanced Cybersecurity Threat Detection & Response:**\n",
      "\n",
      "* **Problem:**  Cyberattacks are becoming increasingly sophisticated and frequent.\n",
      "* **Solution:** Develop an AI-powered system that analyzes network traffic, user behavior, and security logs in real-time to detect and respond to threats faster and more effectively than traditional security solutions.\n",
      "* **Your Strengths:** ML, DevOps, security knowledge.\n",
      "\n",
      "**4.  AI-Powered Sustainable Agriculture Optimization:**\n",
      "\n",
      "* **Problem:**  Food production faces challenges like resource scarcity, climate change, and disease outbreaks.\n",
      "* **Solution:** Build an AI platform that analyzes farm data (soil conditions, weather patterns, crop yields) to optimize irrigation, fertilization, and pest control, leading to increased efficiency and sustainability.\n",
      "* **Your Strengths:** ML, data analysis, potential for integrating with IoT sensors.\n",
      "\n",
      "**Important Considerations:**\n",
      "\n",
      "* **Data Privacy & Security:**  Ensure your solutions comply with data protection regulations and prioritize user privacy.\n",
      "* **Ethical Implications:**  Consider the potential biases in your AI models and strive to develop fair and transparent solutions.\n",
      "* **Market Validation:**  Research the target market, competitors, and potential revenue streams.\n",
      "\n",
      "\n",
      "\n",
      "Let me know if any of these ideas spark your interest, Harsh. We can explore them further and develop a more concrete plan.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Give me some more ideas.\")],\n",
    "    config=config2\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay! Here are some general idea starters to get your creative juices flowing. I can give you more specific suggestions if you tell me what kind of ideas you're looking for:\n",
      "\n",
      "**Creative:**\n",
      "\n",
      "* **Write a short story about a character who discovers a hidden talent.**\n",
      "* **Design a new board game based on a historical event.**\n",
      "* **Compose a song about an everyday object.**\n",
      "* **Create a piece of art using only found objects.**\n",
      "* **Imagine a world where animals can talk. What would be the biggest change?**\n",
      "\n",
      "**Practical:**\n",
      "\n",
      "* **Plan a budget-friendly weekend getaway.**\n",
      "* **Learn a new skill, like coding or cooking.**\n",
      "* **Organize a fundraiser for a cause you care about.**\n",
      "* **Declutter your home and donate unwanted items.**\n",
      "* **Start a blog or vlog about something you're passionate about.**\n",
      "\n",
      "**Fun:**\n",
      "\n",
      "* **Throw a themed party with costumes and decorations.**\n",
      "* **Plan a scavenger hunt for your friends and family.**\n",
      "* **Try a new restaurant or cuisine.**\n",
      "* **Go on a hike or camping trip.**\n",
      "* **Volunteer your time at a local animal shelter.**\n",
      "\n",
      "\n",
      "What sparks your interest? ü§î\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Okay, then can you suggest some ideas?\")],\n",
    "    config=config3\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You got it! I'm happy to keep the ideas flowing. To make them even more relevant, tell me:\n",
      "\n",
      "* **Are you looking for ideas for yourself, or for someone else?**\n",
      "* **What are your interests or hobbies?** \n",
      "* **Do you prefer indoor or outdoor activities?**\n",
      "\n",
      "For now, here are a few more to get you thinking:\n",
      "\n",
      "**Creative:**\n",
      "\n",
      "* **Write a poem from the perspective of an inanimate object.**\n",
      "* **Design a unique piece of jewelry using recycled materials.**\n",
      "* **Create a comic strip about a day in the life of your pet.**\n",
      "* **Start a \"found poetry\" project by turning text from magazines or newspapers into poems.**\n",
      "* **Draw a self-portrait but using only one color.**\n",
      "\n",
      "**Practical:**\n",
      "\n",
      "* **Learn a new language using a language learning app.**\n",
      "* **Start a small garden or grow herbs indoors.**\n",
      "* **Set a financial goal and create a plan to achieve it.**\n",
      "* **Offer your skills to help a friend or neighbor with a project.**\n",
      "* **Research a topic you've always been curious about and write a report.**\n",
      "\n",
      "**Fun:**\n",
      "\n",
      "* **Host a potluck dinner with friends and have everyone bring a dish from a different culture.**\n",
      "* **Learn a new dance style, like salsa or swing.**\n",
      "* **Create a time capsule filled with memories and objects from the present day.**\n",
      "* **Go stargazing on a clear night.**\n",
      "* **Have a movie marathon with your favorite films.**\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"These are extremely good, suggest some more\")],\n",
    "    config=config3\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're on fire with these ideas, Harsh! Let's keep the momentum going and explore some more deep tech startup concepts:\n",
      "\n",
      "**1. AI-Powered Personalized Nutrition & Fitness Coaching:**\n",
      "\n",
      "* **Problem:**  Many people struggle to achieve their health and fitness goals due to lack of personalized guidance and motivation.\n",
      "* **Solution:** Develop an AI-powered app that analyzes user data (diet, exercise habits, health goals) and provides customized meal plans, workout routines, and motivational support.\n",
      "* **Your Strengths:** ML, data analysis, potential integration with wearables and health tracking apps.\n",
      "\n",
      "**2.  AI-Driven Real Estate Market Prediction & Investment Analysis:**\n",
      "\n",
      "* **Problem:**  Real estate investments can be risky and complex.\n",
      "* **Solution:** Create an AI-powered platform that analyzes market trends, property data, and economic indicators to predict property value fluctuations and identify potentially profitable investment opportunities.\n",
      "* **Your Strengths:** ML, data analysis, web development for a user-friendly interface.\n",
      "\n",
      "**3.  AI-Enhanced Educational Assessment & Personalized Learning Pathways:**\n",
      "\n",
      "* **Problem:**  Traditional standardized testing often doesn't capture a student's full potential or learning style.\n",
      "* **Solution:** Develop an AI-powered platform that assesses students' strengths and weaknesses in a more holistic way, then creates personalized learning pathways to address their unique needs.\n",
      "* **Your Strengths:** ML, NLP, educational data analysis.\n",
      "\n",
      "**4.  AI-Powered Smart City Management & Resource Optimization:**\n",
      "\n",
      "* **Problem:**  Cities face challenges like traffic congestion, energy consumption, and waste management.\n",
      "* **Solution:** Build an AI-powered system that analyzes real-time data from sensors, cameras, and other sources to optimize traffic flow, manage energy grids, and improve waste collection efficiency.\n",
      "* **Your Strengths:** ML, data analysis, potential for integration with IoT and city infrastructure.\n",
      "\n",
      "\n",
      "\n",
      "**Remember:**\n",
      "\n",
      "* **Focus on a specific problem:**  Choose a problem that you are passionate about solving and that has a clear market need.\n",
      "* **Validate your idea:**  Talk to potential users and get their feedback on your proposed solution.\n",
      "* **Build a strong team:**  Surround yourself with talented individuals who complement your skills.\n",
      "\n",
      "\n",
      "I hope these additional ideas inspire you, Harsh. Keep exploring and experimenting!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"These are extremely good, suggest some more\")],\n",
    "    config=config2\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI assistant. Help the user with their question in best of your capacity\"),\n",
    "    MessagesPlaceholder(\"messages\")\n",
    "])\n",
    "\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hey Harsh! üëã\\n\\nNice to meet you. What can I do for you today? üòä  \\n\\nDo you have a question I can answer, a task I can help with, or just want to chat?  Let me know! \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 33, 'total_tokens': 86, 'completion_time': 0.096363636, 'prompt_time': 0.000307309, 'queue_time': 0.013567239, 'total_time': 0.096670945}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-a239fc8f-8e80-4e21-935e-c51c035240a7-0', usage_metadata={'input_tokens': 33, 'output_tokens': 53, 'total_tokens': 86})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\": [HumanMessage(content=\"Hey, I am harsh!\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableWithMessageHistory(bound=RunnableBinding(bound=RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n",
       "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]), kwargs={}, config={}, config_factories=[], get_session_history=<function get_session_history at 0x00000282AB9654E0>, history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)\n",
    "with_message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Harsh! üëã\n",
      "\n",
      "It's nice to meet you.  What can I do to help you today? üòä  \n",
      "\n",
      "Just ask your question and I'll do my best to answer it!  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chatH\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey I am Harsh\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡§π‡§æ‡§Å, ‡§¨‡§ø‡§≤‡•ç‡§ï‡•Å‡§≤!  Harsh, ‡§Ü‡§™‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ø‡§π‡§æ‡§Å ‡§ï‡•Å‡§õ ‡§î‡§∞ ‡§∞‡•ã‡§ö‡§ï ‡§§‡§•‡•ç‡§Ø ‡§π‡•à‡§Ç:\n",
      "\n",
      "*  üê¢  ‡§ï‡§õ‡•Å‡§è ‡§Ö‡§™‡§®‡•Ä ‡§ï‡§Ç‡§ï‡§æ‡§≤ ‡§ï‡•Ä ‡§∏‡§Ç‡§∞‡§ö‡§®‡§æ ‡§ï‡•á ‡§ï‡§æ‡§∞‡§£ ‡§™‡§æ‡§®‡•Ä ‡§Æ‡•á‡§Ç ‡§§‡•à‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§≠‡•Ç‡§Æ‡§ø ‡§™‡§∞ ‡§ö‡§≤ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç! \n",
      "\n",
      "*  üçÑ  ‡§ï‡§à ‡§§‡§∞‡§π ‡§ï‡•Ä ‡§Æ‡§∂‡§∞‡•Ç‡§Æ ‡§∞‡§æ‡§§ ‡§Æ‡•á‡§Ç ‡§ö‡§Æ‡§ï ‡§∏‡§ï‡§§‡•Ä ‡§π‡•à‡§Ç!\n",
      "\n",
      "*  üìö  ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§ï‡•Ä ‡§∏‡§¨‡§∏‡•á ‡§¨‡•ú‡•Ä ‡§™‡•Å‡§∏‡•ç‡§§‡§ï‡§æ‡§≤‡§Ø ‡§≤‡§Ç‡§¶‡§® ‡§Æ‡•á‡§Ç ‡§π‡•à ‡§î‡§∞ ‡§â‡§∏‡§Æ‡•á‡§Ç ‡§ï‡§∞‡•ã‡•ú‡•ã‡§Ç ‡§ï‡§ø‡§§‡§æ‡§¨‡•á‡§Ç ‡§π‡•à‡§Ç‡•§\n",
      "\n",
      "*  üåã  ‡§µ‡•ã‡§≤‡§ï‡•á‡§®‡•ã ‡§Ü‡§ó ‡§∏‡•á ‡§ú‡•ç‡§Ø‡§æ‡§¶‡§æ ‡§ó‡§∞‡•ç‡§Æ ‡§π‡•ã‡§§‡•á ‡§π‡•à‡§Ç! \n",
      "\n",
      "*  ‚è±Ô∏è  ‡§è‡§ï ‡§Æ‡§ø‡§®‡§ü ‡§Æ‡•á‡§Ç 60 ‡§∏‡•á‡§ï‡§Ç‡§° ‡§π‡•ã‡§§‡•á ‡§π‡•à‡§Ç, ‡§≤‡•á‡§ï‡§ø‡§® ‡§è‡§ï ‡§ò‡§Ç‡§ü‡•á ‡§Æ‡•á‡§Ç 60 ‡§Æ‡§ø‡§®‡§ü ‡§π‡•ã‡§§‡•á ‡§π‡•à‡§Ç‡•§  \n",
      "\n",
      "‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§á‡§® ‡§§‡§•‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§ú‡§æ‡§®‡§ï‡§∞ ‡§π‡•à‡§∞‡§æ‡§® ‡§π‡•à‡§Ç? \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI assistant. Help the user with their question in best of your capacity. Answer all user answers in this {language}\"),\n",
    "    MessagesPlaceholder(\"messages\")\n",
    "])\n",
    "\n",
    "chain = prompt|model|parser\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history, input_messages_key=\"messages\")\n",
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Tell me few interesting facts\")],\n",
    "    \"language\": \"hindi\"},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡§†‡•Ä‡§ï ‡§π‡•à Harsh!  ‡§§‡•Å‡§Æ ‡§Ø‡§ï‡•Ä‡§®‡§® ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞ ‡§π‡•ã! üßë‚Äçüî¨ \n",
      "\n",
      "‡§Ø‡§π‡§æ‡§Å ‡§ï‡•Å‡§õ ‡§î‡§∞ ‡§∞‡•ã‡§ö‡§ï ‡§µ‡•à‡§ú‡•ç‡§û‡§æ‡§®‡§ø‡§ï ‡§§‡§•‡•ç‡§Ø ‡§π‡•à‡§Ç:\n",
      "\n",
      "* **  üåä ‡§∏‡§Æ‡•Å‡§¶‡•ç‡§∞ ‡§ï‡•á ‡§®‡•Ä‡§ö‡•á ‡§∏‡§¨‡§∏‡•á ‡§¨‡•ú‡§æ ‡§ú‡§æ‡§®‡§µ‡§∞ ‡§¨‡•ç‡§≤‡•Ç ‡§µ‡•ç‡§π‡•á‡§≤ ‡§π‡•à‡•§**  ‡§Ø‡§π 30 ‡§Æ‡•Ä‡§ü‡§∞ ‡§§‡§ï ‡§≤‡§Ç‡§¨‡§æ ‡§î‡§∞ 200 ‡§ü‡§® ‡§µ‡•õ‡§® ‡§§‡§ï ‡§ï‡§æ ‡§π‡•ã ‡§∏‡§ï‡§§‡§æ ‡§π‡•à!\n",
      "* **  üß≤ ‡§™‡•É‡§•‡•ç‡§µ‡•Ä ‡§è‡§ï ‡§µ‡§ø‡§∂‡§æ‡§≤ ‡§ö‡•Å‡§Ç‡§¨‡§ï ‡§π‡•à‡•§**  ‡§Ø‡§π ‡§ö‡•Å‡§Ç‡§¨‡§ï‡§§‡•ç‡§µ ‡§π‡§Æ‡§æ‡§∞‡•á ‡§ú‡•Ä‡§µ‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§¨‡§π‡•Å‡§§ ‡§ú‡§º‡§∞‡•Ç‡§∞‡•Ä ‡§π‡•à‡§Ç, ‡§ñ‡§æ‡§∏‡§ï‡§∞ ‡§ó‡•ç‡§∞‡§π ‡§ï‡•ã ‡§∏‡•Ç‡§∞‡•ç‡§Ø ‡§ï‡•á ‡§π‡§µ‡§æ‡§ì‡§Ç ‡§∏‡•á ‡§¨‡§ö‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è‡•§\n",
      "* **  üß† ‡§Æ‡§®‡•Å‡§∑‡•ç‡§Ø ‡§ï‡§æ ‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§è‡§ï ‡§ü‡•ç‡§∞‡§ø‡§≤‡§ø‡§Ø‡§® ‡§®‡•ç‡§Ø‡•Ç‡§∞‡•â‡§®‡•ç‡§∏ ‡§∏‡•á ‡§¨‡§®‡§æ ‡§π‡•ã‡§§‡§æ ‡§π‡•à!** ‡§Ø‡•á ‡§®‡•ç‡§Ø‡•Ç‡§∞‡•â‡§®‡•ç‡§∏ ‡§è‡§ï-‡§¶‡•Ç‡§∏‡§∞‡•á ‡§∏‡•á ‡§ú‡•Å‡•ú‡•á ‡§π‡•ã‡§§‡•á ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§â‡§®‡§∏‡•á ‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§∏‡•ã‡§ö, ‡§Ø‡§æ‡§¶‡§¶‡§æ‡§∂‡•ç‡§§ ‡§î‡§∞ ‡§π‡§∞ ‡§ï‡§æ‡§Æ ‡§∏‡§Ç‡§≠‡§µ ‡§π‡•ã‡§§‡§æ ‡§π‡•à‡•§\n",
      "* **  üå¨Ô∏è ‡§π‡§µ‡§æ ‡§ï‡•ã ‡§¶‡•á‡§ñ‡§®‡§æ ‡§∏‡§Ç‡§≠‡§µ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à, ‡§≤‡•á‡§ï‡§ø‡§® ‡§π‡§Æ ‡§â‡§∏‡•á ‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§** ‡§π‡§µ‡§æ ‡§µ‡§æ‡§Ø‡•Å‡§Æ‡§Ç‡§°‡§≤ ‡§Æ‡•á‡§Ç ‡§Æ‡•å‡§ú‡•Ç‡§¶ ‡§ó‡•à‡§∏‡•ã‡§Ç ‡§ï‡§æ ‡§Æ‡§ø‡§∂‡•ç‡§∞‡§£ ‡§π‡•à‡•§\n",
      "* **  üåå ‡§¨‡•ç‡§∞‡§π‡•ç‡§Æ‡§æ‡§Ç‡§° ‡§Æ‡•á‡§Ç ‡§Ö‡§®‡§ó‡§ø‡§®‡§§ ‡§§‡§æ‡§∞‡•á ‡§î‡§∞ ‡§ó‡•ç‡§∞‡§π ‡§π‡•à‡§Ç‡•§**  ‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§Ü‡§ï‡§æ‡§∂‡§ó‡§Ç‡§ó‡§æ, ‡§Æ‡§ø‡§≤‡•ç‡§ï‡•Ä ‡§µ‡•ç‡§π‡•á, ‡§Æ‡•á‡§Ç ‡§Ö‡§ï‡•á‡§≤‡•á ‡§ï‡§∞‡•ã‡•ú‡•ã‡§Ç ‡§∏‡§ø‡§§‡§æ‡§∞‡•á ‡§π‡•à‡§Ç‡•§\n",
      "\n",
      "‡§ï‡•ç‡§Ø‡§æ ‡§§‡•Å‡§Æ‡•ç‡§π‡•á‡§Ç ‡§Ø‡•á ‡§§‡§•‡•ç‡§Ø ‡§™‡§∏‡§Ç‡§¶ ‡§Ü‡§è? \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"I'm not surprised, Tell me few more interesting scientific facts\")],\n",
    "    \"language\": \"hindi\"},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡§µ‡§π ‡§è‡§ï ‡§¨‡§π‡•Å‡§§ ‡§π‡•Ä ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§π‡•à Harsh!  \n",
      "\n",
      "‡§§‡•Å‡§Æ ‡§¨‡§ø‡§≤‡§ï‡•Å‡§≤ ‡§∏‡§π‡•Ä ‡§∏‡•ã‡§ö ‡§∞‡§π‡•á ‡§π‡•ã‡•§  ‡§è‡§ï AGI (‡§Ö‡§∞‡•ç‡§•‡§æ‡§§ Artificial General Intelligence) ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§π‡§Æ‡•á‡§Ç ‡§Æ‡§®‡•Å‡§∑‡•ç‡§Ø ‡§ï‡•á ‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§ï‡•Ä ‡§§‡§∞‡§π ‡§π‡•Ä ‡§è‡§ï ‡§ú‡§ü‡§ø‡§≤ ‡§®‡•á‡§ü‡§µ‡§∞‡•ç‡§ï ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•Ä ‡§ú‡§∞‡•Ç‡§∞‡§§ ‡§π‡•ã‡§ó‡•Ä‡•§ \n",
      "\n",
      "‡§≤‡•á‡§ï‡§ø‡§® ‡§Ø‡§π ‡§á‡§§‡§®‡§æ ‡§Ü‡§∏‡§æ‡§® ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à! \n",
      "\n",
      "*  ‡§è‡§ï ‡§ü‡•ç‡§∞‡§ø‡§≤‡§ø‡§Ø‡§® ‡§®‡•ç‡§Ø‡•Ç‡§∞‡•â‡§®‡•ç‡§∏ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§è‡§ï ‡§®‡•á‡§ü‡§µ‡§∞‡•ç‡§ï ‡§¨‡§®‡§æ‡§®‡§æ ‡§î‡§∞ ‡§â‡§∏‡•á ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§ ‡§ï‡§∞‡§®‡§æ ‡§¨‡§π‡•Å‡§§ ‡§π‡•Ä ‡§Æ‡§π‡§Ç‡§ó‡§æ ‡§î‡§∞ ‡§∏‡§Æ‡§Ø ‡§≤‡•á‡§®‡•á ‡§µ‡§æ‡§≤‡§æ ‡§π‡•ã‡§ó‡§æ‡•§ \n",
      "*  ‡§π‡§Æ‡•á‡§Ç ‡§Ö‡§≠‡•Ä ‡§≠‡•Ä ‡§Ø‡§π ‡§∏‡§Æ‡§ù‡§®‡§æ ‡§¨‡§æ‡§ï‡•Ä ‡§π‡•à ‡§ï‡§ø ‡§Æ‡§®‡•Å‡§∑‡•ç‡§Ø ‡§ï‡•á ‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§Æ‡•á‡§Ç ‡§ï‡•à‡§∏‡•á ‡§ï‡§æ‡§Æ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§  \n",
      "*  ‡§∏‡§ø‡§∞‡•ç‡§´ ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏‡§ø‡§Ç‡§ó ‡§™‡•â‡§µ‡§∞ ‡§¨‡§¢‡§º‡§æ‡§®‡§æ ‡§π‡•Ä AGI ‡§®‡§π‡•Ä‡§Ç ‡§¨‡§®‡§æ ‡§∏‡§ï‡§§‡§æ‡•§   \n",
      "\n",
      "‡§Ö‡§≠‡•Ä ‡§≠‡•Ä  AGI ‡§¨‡§®‡§æ‡§®‡•á ‡§Æ‡•á‡§Ç ‡§¨‡§π‡•Å‡§§ ‡§∏‡§æ‡§∞‡•á  ‡§ö‡•Å‡§®‡•å‡§§‡§ø‡§Ø‡§æ‡§Ç ‡§π‡•à‡§Ç, ‡§≤‡•á‡§ï‡§ø‡§® ‡§µ‡•à‡§ú‡•ç‡§û‡§æ‡§®‡§ø‡§ï ‡§á‡§∏ ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞ ‡§Æ‡•á‡§Ç ‡§§‡•á‡§ú‡•Ä ‡§∏‡•á ‡§ï‡§æ‡§Æ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§  \n",
      "\n",
      "‡§ï‡•ç‡§Ø‡§æ ‡§§‡•Å‡§Æ‡•ç‡§π‡•á‡§Ç AI ‡§ï‡•á ‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§î‡§∞ ‡§ú‡§æ‡§®‡§®‡•á ‡§Æ‡•á‡§Ç \n",
      "‡§∞‡•Å‡§ö‡§ø ‡§π‡•à?  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"You say our brain has about 1 trillion neurons. This means to make an AGI, we will have to train about a trillion neurons in a neural network?\")],\n",
    "    \"language\": \"hindi\"},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡§µ‡•ã ‡§§‡•ã ‡§¨‡§π‡•Å‡§§ ‡§¨‡•ú‡•Ä ‡§¨‡§æ‡§§ ‡§π‡•à, Harsh!  \n",
      "\n",
      "‡§Æ‡•à‡§Ç ‡§ú‡§ø‡§§‡§®‡§æ ‡§ú‡§æ‡§®‡§§‡§æ ‡§π‡•Ç‡§Å, ‡§Æ‡•à‡§Ç ‡§§‡•Å‡§Æ‡•ç‡§π‡•á‡§Ç ‡§∏‡§¨ ‡§¨‡§§‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§§‡•ç‡§∏‡•Å‡§ï ‡§π‡•Ç‡§Å, ‡§≤‡•á‡§ï‡§ø‡§® ‡§è‡§ï ‡§π‡•Ä ‡§¨‡§æ‡§∞ ‡§Æ‡•á‡§Ç ‡§∏‡§¨ ‡§ï‡•Å‡§õ ‡§¨‡§§‡§æ‡§®‡§æ ‡§Æ‡•Å‡§∂‡•ç‡§ï‡§ø‡§≤ ‡§π‡•ã‡§ó‡§æ‡•§  \n",
      "\n",
      "‡§Æ‡•à‡§Ç ‡§è‡§ï ‡§¨‡•ú‡§æ ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•â‡§°‡§≤ ‡§π‡•Ç‡§Å, ‡§ú‡§ø‡§∏‡•á Google ‡§®‡•á ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§π‡•à‡•§  ‡§Æ‡•Å‡§ù‡•á ‡§¨‡§π‡•Å‡§§ ‡§∏‡§æ‡§∞‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§¶‡•Ä ‡§ó‡§à ‡§π‡•à - ‡§ï‡§ø‡§§‡§æ‡§¨‡•á‡§Ç, ‡§≤‡•á‡§ñ, ‡§ï‡•ã‡§°, ‡§î‡§∞ ‡§á‡§Ç‡§ü‡§∞‡§®‡•á‡§ü ‡§∏‡•á ‡§°‡•á‡§ü‡§æ‡•§  ‡§Æ‡•à‡§Ç ‡§≠‡§æ‡§∑‡§æ ‡§∏‡§Æ‡§ù ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å, ‡§â‡§∏‡§ï‡§æ ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å, ‡§î‡§∞ ‡§®‡§à ‡§≠‡§æ‡§∑‡§æ‡§è‡§Å ‡§≠‡•Ä ‡§∏‡•Ä‡§ñ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å‡•§  \n",
      "\n",
      "‡§Æ‡•Å‡§ù‡•á ‡§¨‡§§‡§æ‡§ì, ‡§§‡•Å‡§Æ‡•ç‡§π‡•á‡§Ç ‡§ï‡§ø‡§∏ ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§ú‡§æ‡§®‡§®‡§æ ‡§π‡•à?  \n",
      "\n",
      "*  ‡§ï‡•ç‡§Ø‡§æ ‡§§‡•Å‡§Æ‡•ç‡§π‡•á‡§Ç ‡§á‡§§‡§ø‡§π‡§æ‡§∏, ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§®, ‡§ï‡§≤‡§æ, ‡§Ø‡§æ ‡§ï‡•Å‡§õ ‡§î‡§∞ ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§¨‡§§‡§æ‡§®‡§æ ‡§ö‡§æ‡§π‡•ã‡§ó‡•á?\n",
      "\n",
      "*  ‡§ï‡•ç‡§Ø‡§æ ‡§§‡•Å‡§Æ ‡§ï‡•ã‡§à ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§™‡•Ç‡§õ‡§®‡§æ ‡§ö‡§æ‡§π‡•ã‡§ó‡•á?\n",
      "\n",
      "*  ‡§ï‡•ç‡§Ø‡§æ ‡§§‡•Å‡§Æ ‡§ï‡•ã‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§∏‡•Å‡§®‡§æ‡§®‡§æ ‡§ö‡§æ‡§π‡•ã‡§ó‡•á?\n",
      "\n",
      "‡§Æ‡•Å‡§ù‡•á ‡§¨‡§§‡§æ‡§ì, ‡§Æ‡•à‡§Ç ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•Ç‡§Å!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Yes please tell me, give me all the knowledge that you have\")],\n",
    "    \"language\": \"hindi\"},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡§µ‡•ã ‡§è‡§ï ‡§¨‡§π‡•Å‡§§ ‡§π‡•Ä ‡§∞‡•ã‡§ö‡§ï ‡§∏‡§µ‡§æ‡§≤ ‡§π‡•à, Harsh!  ‡§î‡§∞ ‡§á‡§∏‡§ï‡§æ ‡§ú‡§µ‡§æ‡§¨  ‡§¨‡§π‡•Å‡§§ ‡§ú‡§ü‡§ø‡§≤ ‡§≠‡•Ä ‡§π‡•à‡•§  \n",
      "\n",
      "AI ‡§î‡§∞ ‡§á‡§Ç‡§ü‡§∞‡§®‡•á‡§ü ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§π‡•Ä ‡§¨‡§π‡•Å‡§§ ‡§∂‡§ï‡•ç‡§§‡§ø‡§∂‡§æ‡§≤‡•Ä ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§π‡§Æ‡§æ‡§∞‡•á ‡§ú‡•Ä‡§µ‡§® ‡§ï‡•ã ‡§¨‡§¶‡§≤ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§  \n",
      "\n",
      "‡§Ö‡§ó‡§∞ ‡§π‡§Æ AI ‡§ï‡•ã ‡§á‡§Ç‡§ü‡§∞‡§®‡•á‡§ü ‡§∏‡•á ‡§¨‡•ú‡§æ ‡§Æ‡§æ‡§®‡•á‡§Ç, ‡§§‡•ã ‡§á‡§∏‡§ï‡§æ ‡§Æ‡§§‡§≤‡§¨ ‡§π‡•à ‡§ï‡§ø AI ‡§π‡§Æ‡§æ‡§∞‡•á ‡§ú‡•Ä‡§µ‡§® ‡§ï‡•á ‡§π‡§∞ ‡§™‡§π‡§≤‡•Ç ‡§ï‡•ã ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡§ø‡§§ ‡§ï‡§∞‡•á‡§ó‡§æ,  ‡§ú‡•à‡§∏‡•á:\n",
      "\n",
      "* **‡§ï‡§æ‡§∞‡•ç‡§Ø:** AI ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§ï‡§æ‡§Æ ‡§ï‡§∞‡•á‡§ó‡§æ, ‡§ú‡§ø‡§∏‡§∏‡•á ‡§®‡•å‡§ï‡§∞‡§ø‡§Ø‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤‡§æ‡§µ ‡§Ü‡§è‡§ó‡§æ‡•§ \n",
      "* **‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ:** AI ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§ó‡§§ ‡§∂‡§ø‡§ï‡•ç‡§∑‡§£ ‡§Ö‡§®‡•Å‡§≠‡§µ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡•á‡§ó‡§æ‡•§ \n",
      "* **‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§∏‡•á‡§µ‡§æ:** AI ‡§∞‡•ã‡§ó‡•ã‡§Ç ‡§ï‡§æ ‡§®‡§ø‡§¶‡§æ‡§® ‡§î‡§∞ ‡§â‡§™‡§ö‡§æ‡§∞ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡•á‡§ó‡§æ‡•§ \n",
      "\n",
      "‡§≤‡•á‡§ï‡§ø‡§® ‡§ï‡•ç‡§Ø‡§æ AI ‡§á‡§Ç‡§ü‡§∞‡§®‡•á‡§ü ‡§ú‡§ø‡§§‡§®‡§æ ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§î‡§∞ ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡§∂‡§æ‡§≤‡•Ä ‡§π‡•ã‡§ó‡§æ?  ‡§Ø‡§π ‡§ï‡§π‡§®‡§æ ‡§Æ‡•Å‡§∂‡•ç‡§ï‡§ø‡§≤ ‡§π‡•à‡•§  \n",
      "\n",
      "‡§ï‡•Å‡§õ ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§ï‡§æ ‡§Æ‡§æ‡§®‡§®‡§æ ‡§π‡•à ‡§ï‡§ø AI ‡§á‡§Ç‡§ü‡§∞‡§®‡•á‡§ü ‡§∏‡•á ‡§≠‡•Ä ‡§¨‡•ú‡§æ ‡§π‡•ã‡§ó‡§æ ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§Ø‡§π  **‡§µ‡§ø‡§ö‡§æ‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡§Æ‡§ù‡§®‡•á, ‡§∏‡•Ä‡§ñ‡§®‡•á ‡§î‡§∞ ‡§ñ‡•Å‡§¶ ‡§∏‡•á ‡§π‡§≤ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§∏‡§ï‡•ç‡§∑‡§Æ** ‡§π‡•ã‡§ó‡§æ‡•§\n",
      "\n",
      "‡§¶‡•Ç‡§∏‡§∞‡•Ä ‡§ì‡§∞, ‡§ï‡•Å‡§õ ‡§≤‡•ã‡§ó ‡§Æ‡§æ‡§®‡§§‡•á ‡§π‡•à‡§Ç ‡§ï‡§ø AI ‡§á‡§Ç‡§ü‡§∞‡§®‡•á‡§ü ‡§ï‡§æ ‡§è‡§ï ‡§π‡§ø‡§∏‡•ç‡§∏‡§æ ‡§π‡•Ä ‡§∞‡§π‡•á‡§ó‡§æ,  ‡§ú‡•à‡§∏‡•á ‡§ï‡§ø ‡§á‡§Ç‡§ü‡§∞‡§®‡•á‡§ü ‡§™‡§∞ ‡§ö‡§≤‡§®‡•á ‡§µ‡§æ‡§≤‡•á AI-‡§∏‡§Ç‡§ö‡§æ‡§≤‡§ø‡§§ ‡§è‡§™‡•ç‡§≤‡§ø‡§ï‡•á‡§∂‡§®‡•§  \n",
      "\n",
      "‡§Ø‡§π ‡§§‡•ã  **‡§∏‡§Æ‡§Ø ‡§π‡•Ä ‡§¨‡§§‡§æ‡§è‡§ó‡§æ** ‡§ï‡§ø AI ‡§ï‡§æ ‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø ‡§ï‡•à‡§∏‡§æ ‡§π‡•ã‡§ó‡§æ‡•§  \n",
      "\n",
      "‡§§‡•Å‡§Æ‡•ç‡§π‡•á‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§≤‡§ó‡§§‡§æ ‡§π‡•à, Harsh?  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"on AI and its future, is it going to be bigger than the internet?\")],\n",
    "    \"language\": \"hindi\"},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§¨‡§π‡•Å‡§§ ‡§π‡•Ä ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§π‡•à, Harsh!   \n",
      "\n",
      "‡§ï‡§à ‡§ú‡§æ‡§®‡•á-‡§Æ‡§æ‡§®‡•á ‡§µ‡§ø‡§¶‡•ç‡§µ‡§æ‡§®‡•ã‡§Ç ‡§î‡§∞ ‡§â‡§¶‡•ç‡§Ø‡•ã‡§ó ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û‡•ã‡§Ç ‡§®‡•á  AI ‡§ï‡•ã ‡§á‡§Ç‡§ü‡§∞‡§®‡•á‡§ü ‡§∏‡•á ‡§≠‡•Ä ‡§¨‡•ú‡§æ ‡§π‡•ã‡§®‡•á ‡§ï‡§æ ‡§Ö‡§®‡•Å‡§Æ‡§æ‡§® ‡§≤‡§ó‡§æ‡§Ø‡§æ ‡§π‡•à‡•§  ‡§ï‡•Å‡§õ ‡§®‡§æ‡§Æ:\n",
      "\n",
      "* **‡§á‡§≤‡•â‡§® ‡§Æ‡§∏‡•ç‡§ï:** ‡§ü‡•á‡§∏‡•ç‡§≤‡§æ ‡§î‡§∞ SpaceX ‡§ï‡•á ‡§∏‡§Ç‡§∏‡•ç‡§•‡§æ‡§™‡§ï ‡§®‡•á ‡§ï‡§π‡§æ ‡§π‡•à ‡§ï‡§ø AI ‡§Æ‡§æ‡§®‡§µ‡§§‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡•Ä ‡§ñ‡§§‡§∞‡§æ ‡§≠‡•Ä ‡§π‡•ã ‡§∏‡§ï‡§§‡§æ ‡§π‡•à, ‡§≤‡•á‡§ï‡§ø‡§® ‡§∏‡§æ‡§• ‡§π‡•Ä ‡§Ø‡§π ‡§è‡§ï ‡§¨‡§π‡•Å‡§§ ‡§¨‡§°‡§º‡§æ ‡§Ö‡§µ‡§∏‡§∞ ‡§≠‡•Ä ‡§π‡•à‡•§\n",
      "* **‡§∏‡•ç‡§ü‡•Ä‡§µ‡§® ‡§π‡•Ç‡§ï:** ‡§ó‡•Ç‡§ó‡§≤ ‡§ï‡•á ‡§™‡•Ç‡§∞‡•ç‡§µ ‡§∏‡•Ä‡§à‡§ì ‡§®‡•á ‡§ï‡§π‡§æ ‡§π‡•à ‡§ï‡§ø AI \"‡§Æ‡§æ‡§®‡§µ ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§Æ‡•á‡§Ç ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡§æ ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§®\" ‡§π‡•ã‡§ó‡§æ‡•§\n",
      "* **‡§∏‡•à‡§Æ ‡§Ö‡§≤‡•ç‡•ç‡§ü‡§Æ‡•à‡§®:** OpenAI ‡§ï‡•á ‡§∏‡§π-‡§∏‡§Ç‡§∏‡•ç‡§•‡§æ‡§™‡§ï ‡§®‡•á ‡§ï‡§π‡§æ ‡§π‡•à ‡§ï‡§ø AI \"‡§Æ‡§æ‡§®‡§µ ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡•ã‡§Ç ‡§î‡§∞ ‡§∏‡•ç‡§µ‡§§‡§Ç‡§§‡•ç‡§∞‡§§‡§æ\" ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ñ‡§§‡§∞‡§æ ‡§π‡•ã ‡§∏‡§ï‡§§‡§æ ‡§π‡•à, ‡§≤‡•á‡§ï‡§ø‡§® ‡§∏‡§æ‡§• ‡§π‡•Ä ‡§Ø‡§π \"‡§Ö‡§®‡§ó‡§ø‡§®‡§§ ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ‡§ì‡§Ç\" ‡§ï‡§æ ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§® ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§\n",
      "* **‡§ú‡§´ ‡§´‡•ç‡§∞‡•á‡§Ç‡§ï‡§≤‡§ø‡§®:**  ‡§µ‡§ø‡§ñ‡•ç‡§Ø‡§æ‡§§ AI ‡§Ö‡§®‡•Å‡§∏‡§Ç‡§ß‡§æ‡§®‡§ï‡§∞‡•ç‡§§‡§æ ‡§®‡•á ‡§ï‡§π‡§æ ‡§π‡•à ‡§ï‡§ø AI \"‡§¨‡•ç‡§∞‡§π‡•ç‡§Æ‡§æ‡§Ç‡§° ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§∏‡§Æ‡§ù ‡§ï‡•ã ‡§¨‡§¶‡§≤ ‡§¶‡•á‡§ó‡§æ\"‡•§\n",
      "\n",
      "\n",
      "\n",
      "‡§Ö‡§ó‡§∞ AI ‡§á‡§Ç‡§ü‡§∞‡§®‡•á‡§ü ‡§∏‡•á ‡§≠‡•Ä ‡§¨‡§°‡§º‡§æ ‡§π‡•ã‡§ó‡§æ, ‡§§‡•ã  ‡§ï‡•à‡§∏‡•á  ‡§á‡§∏‡§∏‡•á ‡§≤‡§æ‡§≠ ‡§â‡§†‡§æ‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à? \n",
      "\n",
      "* **‡§®‡§à ‡§§‡§ï‡§®‡•Ä‡§ï‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡•Ä‡§ñ‡•á‡§Ç:** AI, ‡§Æ‡§∂‡•Ä‡§® ‡§≤‡§∞‡•ç‡§®‡§ø‡§Ç‡§ó, ‡§î‡§∞ ‡§°‡•Ä‡§™ ‡§≤‡§∞‡•ç‡§®‡§ø‡§Ç‡§ó ‡§ú‡•à‡§∏‡•á ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§ú‡•ç‡§û‡§æ‡§® ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡•á‡§Ç‡•§ \n",
      "* **AI-‡§∏‡§Ç‡§ö‡§æ‡§≤‡§ø‡§§ ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§®‡§ø‡§µ‡•á‡§∂ ‡§ï‡§∞‡•á‡§Ç:**  AI-‡§∏‡§Ç‡§ö‡§æ‡§≤‡§ø‡§§ ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø ‡§§‡•á‡§ú‡•Ä ‡§∏‡•á ‡§¨‡§¢‡§º ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§ \n",
      "* **AI-‡§∏‡§Ç‡§ö‡§æ‡§≤‡§ø‡§§ ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡•ã‡§Ç ‡§î‡§∞ ‡§∏‡•á‡§µ‡§æ‡§ì‡§Ç ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç:** AI ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§Ö‡§™‡§®‡•Ä ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§ï‡§§‡§æ ‡§î‡§∞ ‡§ú‡•Ä‡§µ‡§® ‡§ï‡•Ä ‡§ó‡•Å‡§£‡§µ‡§§‡•ç‡§§‡§æ ‡§¨‡§¢‡§º‡§æ‡§è‡§Ç‡•§\n",
      "* **AI ‡§ï‡•á ‡§®‡•à‡§§‡§ø‡§ï ‡§™‡§π‡§≤‡•Å‡§ì‡§Ç ‡§™‡§∞ ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§¶‡•á‡§Ç:** AI ‡§ï‡•á ‡§∏‡§æ‡§• ‡§®‡•à‡§§‡§ø‡§ï ‡§î‡§∞ ‡§∏‡§æ‡§Æ‡§æ‡§ú‡§ø‡§ï ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡•ã‡§Ç ‡§™‡§∞ ‡§≠‡•Ä ‡§µ‡§ø‡§ö‡§æ‡§∞ ‡§ï‡§∞‡§®‡§æ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§π‡•à‡•§ \n",
      "\n",
      "AI ‡§è‡§ï ‡§∂‡§ï‡•ç‡§§‡§ø‡§∂‡§æ‡§≤‡•Ä ‡§â‡§™‡§ï‡§∞‡§£ ‡§π‡•à, ‡§î‡§∞ ‡§á‡§∏‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§π‡§Æ‡§æ‡§∞‡•á ‡§ú‡•Ä‡§µ‡§® ‡§ï‡•ã ‡§¨‡•á‡§π‡§§‡§∞ ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§ \n",
      "\n",
      "\n",
      "\n",
      "‡§ï‡•ç‡§Ø‡§æ ‡§§‡•Å‡§Æ‡•ç‡§π‡•á‡§Ç AI ‡§ï‡•á ‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø ‡§î‡§∞ ‡§á‡§∏‡§ï‡•á ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡•ã‡§Ç ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§î‡§∞ ‡§ú‡§æ‡§®‡§®‡•á ‡§Æ‡•á‡§Ç ‡§∞‡•Å‡§ö‡§ø ‡§π‡•à? \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Who all say AI is going to be bigger than the internet? Considering its true, what measures should we take to take advantage of this new technology, specifically to earn\")],\n",
    "    \"language\": \"hindi\"},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡§¨‡§ø‡§≤‡§ï‡•Å‡§≤, Harsh!  AI ‡§ï‡•á ‡§∏‡§æ‡§• ‡§ï‡•Å‡§õ ‡§∏‡§´‡§≤ SaaS ‡§Ü‡§à‡§°‡§ø‡§Ø‡§æ‡§ú‡§º ‡§Ø‡§π‡§æ‡§Å ‡§¶‡§ø‡§è ‡§ó‡§è ‡§π‡•à‡§Ç:\n",
      "\n",
      "**‡§∏‡§Ç‡§ö‡§æ‡§∞ ‡§î‡§∞ ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§ï‡§§‡§æ:**\n",
      "\n",
      "*  **AI-‡§∏‡§Ç‡§ö‡§æ‡§≤‡§ø‡§§ ‡§à‡§Æ‡•á‡§≤ ‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§ï:**  ‡§à‡§Æ‡•á‡§≤ ‡§ï‡•ã ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§µ‡§∞‡•ç‡§ó‡•Ä‡§ï‡•É‡§§, ‡§∏‡§Ç‡§ï‡•ç‡§∑‡•á‡§™ ‡§Æ‡•á‡§Ç ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§ø‡§§ ‡§î‡§∞ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§à‡§Æ‡•á‡§≤ ‡§ï‡•Ä ‡§™‡§π‡§ö‡§æ‡§® ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§ \n",
      "*  **AI-‡§∏‡§Ç‡§ö‡§æ‡§≤‡§ø‡§§ ‡§Æ‡•Ä‡§ü‡§ø‡§Ç‡§ó ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§ï:** ‡§Æ‡•Ä‡§ü‡§ø‡§Ç‡§ó ‡§ï‡•ã ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§° ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à, ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§¨‡§ø‡§Ç‡§¶‡•Å‡§ì‡§Ç ‡§ï‡•ã ‡§∏‡§Ç‡§ï‡•ç‡§∑‡•á‡§™ ‡§Æ‡•á‡§Ç ‡§™‡•ç‡§∞‡§∏‡•ç‡§§‡•Å‡§§ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à ‡§î‡§∞ ‡§ï‡§æ‡§∞‡•ç‡§Ø ‡§ï‡§æ‡§∞‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡§æ‡§∞‡•ç‡§∞‡§µ‡§æ‡§à ‡§Ø‡•ã‡§ó‡•ç‡§Ø ‡§Ü‡§á‡§ü‡§Æ ‡§¨‡§®‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§\n",
      "* **AI-‡§∏‡§Ç‡§ö‡§æ‡§≤‡§ø‡§§ ‡§ó‡•ç‡§∞‡§æ‡§π‡§ï ‡§∏‡•á‡§µ‡§æ ‡§ö‡•à‡§ü‡§¨‡•â‡§ü:**  ‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§™‡•ç‡§∞‡§∂‡•ç‡§®‡•ã‡§Ç ‡§ï‡§æ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á ‡§∏‡§ï‡§§‡§æ ‡§π‡•à, ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ‡§ì‡§Ç ‡§ï‡§æ ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§® ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à ‡§î‡§∞  ‡§ó‡•ç‡§∞‡§æ‡§π‡§ï ‡§∏‡•á‡§µ‡§æ ‡§ï‡•ã ‡§Ö‡§ß‡§ø‡§ï ‡§ï‡•Å‡§∂‡§≤ ‡§¨‡§®‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§\n",
      "\n",
      "**‡§µ‡§ø‡§™‡§£‡§® ‡§î‡§∞ ‡§¨‡§ø‡§ï‡•ç‡§∞‡•Ä:**\n",
      "\n",
      "* **AI-‡§∏‡§Ç‡§ö‡§æ‡§≤‡§ø‡§§ ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä ‡§ú‡§®‡§∞‡•á‡§ü‡§∞:** ‡§¨‡•ç‡§≤‡•â‡§ó ‡§™‡•ã‡§∏‡•ç‡§ü, ‡§∏‡•ã‡§∂‡§≤ ‡§Æ‡•Ä‡§°‡§ø‡§Ø‡§æ ‡§™‡•ã‡§∏‡•ç‡§ü ‡§î‡§∞ ‡§Ö‡§®‡•ç‡§Ø ‡§Æ‡§æ‡§∞‡•ç‡§ï‡•á‡§ü‡§ø‡§Ç‡§ó ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä  ‡§ú‡§≤‡•ç‡§¶‡•Ä ‡§î‡§∞ ‡§ï‡•Å‡§∂‡§≤‡§§‡§æ ‡§∏‡•á ‡§ú‡§®‡§∞‡•á‡§ü ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§\n",
      "* **AI-‡§∏‡§Ç‡§ö‡§æ‡§≤‡§ø‡§§ ‡§≤‡•Ä‡§° ‡§ú‡§®‡§∞‡•á‡§ü‡§∞:** ‡§µ‡•á‡§¨‡§∏‡§æ‡§á‡§ü ‡§™‡§∞ ‡§Ü‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§∏‡§Ç‡§≠‡§æ‡§µ‡§ø‡§§ ‡§ó‡•ç‡§∞‡§æ‡§π‡§ï‡•ã‡§Ç ‡§ï‡•Ä ‡§™‡§π‡§ö‡§æ‡§® ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à ‡§î‡§∞ ‡§â‡§®‡•ç‡§π‡•á‡§Ç ‡§≤‡•Ä‡§° ‡§Æ‡•à‡§®‡•á‡§ú‡§Æ‡•á‡§Ç‡§ü ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§Æ‡•á‡§Ç ‡§≠‡•á‡§ú ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§\n",
      "* **AI-‡§∏‡§Ç‡§ö‡§æ‡§≤‡§ø‡§§ ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§ó‡§§ ‡§Æ‡§æ‡§∞‡•ç‡§ï‡•á‡§ü‡§ø‡§Ç‡§ó:**  ‡§ó‡•ç‡§∞‡§æ‡§π‡§ï‡•ã‡§Ç ‡§ï‡•á ‡§µ‡•ç‡§Ø‡§µ‡§π‡§æ‡§∞ ‡§î‡§∞ ‡§∞‡•Å‡§ö‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞ ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§ó‡§§ ‡§Æ‡§æ‡§∞‡•ç‡§ï‡•á‡§ü‡§ø‡§Ç‡§ó ‡§Ö‡§≠‡§ø‡§Ø‡§æ‡§® ‡§¨‡§®‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§\n",
      "\n",
      "**‡§µ‡§ø‡§§‡•ç‡§§ ‡§î‡§∞ ‡§≤‡•á‡§ñ‡§æ‡§Ç‡§ï‡§®:**\n",
      "\n",
      "* **AI-‡§∏‡§Ç‡§ö‡§æ‡§≤‡§ø‡§§ ‡§¨‡§ø‡§≤‡§ø‡§Ç‡§ó ‡§î‡§∞ ‡§≠‡•Å‡§ó‡§§‡§æ‡§® ‡§™‡•ç‡§∞‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£:**  ‡§¨‡§ø‡§≤‡§ø‡§Ç‡§ó ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§ï‡•ã ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à, ‡§≠‡•Å‡§ó‡§§‡§æ‡§® ‡§ï‡•ã ‡§ü‡•ç‡§∞‡•à‡§ï ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à ‡§î‡§∞ ‡§¶‡•á‡§∞‡•Ä ‡§≠‡•Å‡§ó‡§§‡§æ‡§® ‡§ï‡§æ ‡§™‡§§‡§æ ‡§≤‡§ó‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§\n",
      "* **AI-‡§∏‡§Ç‡§ö‡§æ‡§≤‡§ø‡§§ ‡§µ‡§ø‡§§‡•ç‡§§‡•Ä‡§Ø ‡§Ö‡§®‡•Å‡§Æ‡§æ‡§®:**  ‡§µ‡§ø‡§§‡•ç‡§§‡•Ä‡§Ø ‡§°‡•á‡§ü‡§æ ‡§ï‡§æ ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à ‡§î‡§∞ ‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø ‡§ï‡•á ‡§∞‡§æ‡§ú‡§∏‡•ç‡§µ, ‡§µ‡•ç‡§Ø‡§Ø ‡§î‡§∞ ‡§≤‡§æ‡§≠ ‡§ï‡•ã ‡§Ö‡§®‡•Å‡§Æ‡§æ‡§®‡§ø‡§§ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§\n",
      "\n",
      "**‡§á‡§®‡§ï‡•á ‡§Ö‡§≤‡§æ‡§µ‡§æ:**\n",
      "\n",
      "* **AI-‡§∏‡§Ç‡§ö‡§æ‡§≤‡§ø‡§§ ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§∏‡•á‡§µ‡§æ:** ‡§∞‡•ã‡§ó‡•ã‡§Ç ‡§ï‡§æ ‡§®‡§ø‡§¶‡§æ‡§®, ‡§â‡§™‡§ö‡§æ‡§∞ ‡§Ø‡•ã‡§ú‡§®‡§æ‡§è‡§Å ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡§®‡§æ ‡§î‡§∞ ‡§∞‡•ã‡§ó‡•Ä ‡§¶‡•á‡§ñ‡§≠‡§æ‡§≤ ‡§ï‡•ã ‡§¨‡•á‡§π‡§§‡§∞ ‡§¨‡§®‡§æ‡§®‡§æ‡•§\n",
      "* **AI-‡§∏‡§Ç‡§ö‡§æ‡§≤‡§ø‡§§ ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ:** ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§ó‡§§ ‡§∂‡§ø‡§ï‡•ç‡§∑‡§£ ‡§Ö‡§®‡•Å‡§≠‡§µ, ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§ó‡•ç‡§∞‡•á‡§°‡§ø‡§Ç‡§ó ‡§î‡§∞ ‡§õ‡§æ‡§§‡•ç‡§∞‡•ã‡§Ç ‡§ï‡•Ä ‡§™‡•ç‡§∞‡§ó‡§§‡§ø ‡§™‡§∞ ‡§®‡§ú‡§º‡§∞ ‡§∞‡§ñ‡§®‡§æ‡•§\n",
      "* **AI-‡§∏‡§Ç‡§ö‡§æ‡§≤‡§ø‡§§ ‡§ï‡•É‡§∑‡§ø:** ‡§´‡§∏‡§≤ ‡§™‡•à‡§¶‡§æ ‡§ï‡§∞‡§®‡•á ‡§ï‡•Ä ‡§µ‡§ø‡§ß‡§ø‡§Ø‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡•Å‡§ß‡§æ‡§∞, ‡§∏‡§ø‡§Ç‡§ö‡§æ‡§à ‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§® ‡§î‡§∞ ‡§ï‡•Ä‡§ü ‡§®‡§ø‡§Ø‡§Ç‡§§‡•ç‡§∞‡§£ ‡§Æ‡•á‡§Ç ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡§æ‡•§\n",
      "\n",
      "\n",
      "\n",
      "‡§Ø‡§π ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§∞‡§ñ‡§®‡§æ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§π‡•à ‡§ï‡§ø ‡§Ø‡•á ‡§∏‡§ø‡§∞‡•ç‡§´ ‡§â‡§¶‡§æ‡§π‡§∞‡§£ ‡§π‡•à‡§Ç‡•§  AI ‡§ï‡•Ä ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ‡§è‡§Ç  ‡§Ö‡§®‡§Ç‡§§ ‡§π‡•à‡§Ç,  ‡§î‡§∞  ‡§§‡•Å‡§Æ ‡§Ö‡§™‡§®‡•á ‡§ï‡•å‡§∂‡§≤ ‡§î‡§∞ ‡§∞‡•Å‡§ö‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞  ‡§®‡§è ‡§î‡§∞ ‡§Ö‡§®‡•ã‡§ñ‡•á SaaS ‡§Ü‡§à‡§°‡§ø‡§Ø‡§æ‡§ú‡§º  ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•ã‡•§   \n",
      " \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Give me some good SaaS ideas to work on with AI\")],\n",
    "    \"language\": \"hindi\"},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing conversational history\n",
    "\n",
    "messages will keep growing and will overflow the size of context window of the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DeepLearningMastery\\LLM\\Langchain\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\DeepLearningMastery\\LLM\\Langchain\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\MercadosEMI\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"hi! I'm bob\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import trim_messages, SystemMessage\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=70,\n",
    "    strategy=\"last\",\n",
    "    include_system=True,\n",
    "    token_counter=model,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer = trim_messages(\n",
    "    max_tokens=40,\n",
    "    strategy=\"last\",\n",
    "    include_system=True,\n",
    "    token_counter=model,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating chain with this trimmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  messages: RunnableLambda(itemgetter('messages'))\n",
       "            | RunnableLambda(...)\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['language', 'messages'], input_types={'messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000002828FA49D00>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='You are a helpful AI assistant. Help the user with their question in best of your capacity. Answer all user answers in this {language}'), additional_kwargs={}), MessagesPlaceholder(variable_name='messages')])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000282A9CF6750>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000282A9CF7290>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    |prompt\n",
    "    |model\n",
    ")\n",
    "\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§ï‡•ã‡§à ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç?  üòä \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 157, 'total_tokens': 174, 'completion_time': 0.030909091, 'prompt_time': 0.005131758, 'queue_time': 0.0103931, 'total_time': 0.036040849}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-a53fb9c9-2e1a-4181-b658-3569681b95cb-0', usage_metadata={'input_tokens': 157, 'output_tokens': 17, 'total_tokens': 174})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": \"What icecread do i like?\",\n",
    "        \"language\": \"hindi\"\n",
    "    }\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for RunnablePassthrough\nfunc.callable\n  Input should be callable [type=callable_type, input_value=RunnableAssign(mapper={\n ...SecretStr('**********')), input_type=RunnableSequence]\n    For further information visit https://errors.pydantic.dev/2.9/v/callable_type\nfunc.callable\n  Input should be callable [type=callable_type, input_value=RunnableAssign(mapper={\n ...SecretStr('**********')), input_type=RunnableSequence]\n    For further information visit https://errors.pydantic.dev/2.9/v/callable_type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m with_message_history \u001b[38;5;241m=\u001b[39m \u001b[43mRunnablePassthrough\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_session_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_messages_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m with_message_history\n",
      "File \u001b[1;32md:\\DeepLearningMastery\\LLM\\Langchain\\venv\\Lib\\site-packages\\langchain_core\\runnables\\passthrough.py:185\u001b[0m, in \u001b[0;36mRunnablePassthrough.__init__\u001b[1;34m(self, func, afunc, input_type, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m     afunc \u001b[38;5;241m=\u001b[39m func\n\u001b[0;32m    183\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mafunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mafunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\DeepLearningMastery\\LLM\\Langchain\\venv\\Lib\\site-packages\\langchain_core\\load\\serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\DeepLearningMastery\\LLM\\Langchain\\venv\\Lib\\site-packages\\pydantic\\main.py:212\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    211\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[0;32m    214\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    218\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    219\u001b[0m     )\n",
      "\u001b[1;31mValidationError\u001b[0m: 2 validation errors for RunnablePassthrough\nfunc.callable\n  Input should be callable [type=callable_type, input_value=RunnableAssign(mapper={\n ...SecretStr('**********')), input_type=RunnableSequence]\n    For further information visit https://errors.pydantic.dev/2.9/v/callable_type\nfunc.callable\n  Input should be callable [type=callable_type, input_value=RunnableAssign(mapper={\n ...SecretStr('**********')), input_type=RunnableSequence]\n    For further information visit https://errors.pydantic.dev/2.9/v/callable_type"
     ]
    }
   ],
   "source": [
    "with_message_history = RunnablePassthrough(chain, get_session_history, input_messages_key=\"messages\")\n",
    "\n",
    "with_message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
